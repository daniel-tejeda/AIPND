{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Normalization\n",
    "\n",
    "In machine learning we use large amounts of data to train our models. Some machine learning algorithms may require that the data is *normalized* in order to work correctly. The idea of normalization, also known as *feature scaling*, is to ensure that all the data is on a similar scale, *i.e.* that all the data takes on a similar range of values. For example, we might have a dataset that has values between 0 and 5,000. By normalizing the data we can make the range of values be between 0 and 1.\n",
    "\n",
    "In this lab, you will be performing a different kind of feature scaling known as *mean normalization*. Mean normalization will scale the data, but instead of making the values be between 0 and 1, it will distribute the values evenly in some small interval around zero. For example, if we have a dataset that has values between 0 and 5,000, after mean normalization the range of values will be distributed in some small range around 0, for example between -3 to 3. Because the range of values are distributed evenly around zero, this guarantees that the average (mean) of all elements will be zero. Therefore, when you perform *mean normalization* your data will not only be scaled but it will also have an average of zero. \n",
    "\n",
    "# To Do:\n",
    "\n",
    "You will start by importing NumPy and creating a rank 2 ndarray of random integers between 0 and 5,000 (inclusive) with 1000 rows and 20 columns. This array will simulate a dataset with a wide range of values. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 20)\n",
      "[[4944 1753  618 ..., 2236 4023 2851]\n",
      " [3186 4398  145 ...,  402 3263 3328]\n",
      " [3238 4134  280 ..., 4112 1092 4867]\n",
      " ..., \n",
      " [3376 3492 4558 ..., 4259 4818  432]\n",
      " [ 429  340 1671 ..., 2637 1478 4139]\n",
      " [1723 1142 3604 ..., 4166 3183 3238]]\n"
     ]
    }
   ],
   "source": [
    "# import NumPy into Python\n",
    "import numpy as np\n",
    "\n",
    "# Create a 1000 x 20 ndarray with random integers in the half-open interval [0, 5001).\n",
    "X = np.random.randint(low=0, high=5001, size=(1000,20))\n",
    "\n",
    "# print the shape of X\n",
    "print(X.shape)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you created the array we will mean normalize it. We will perform mean normalization using the following equation:\n",
    "\n",
    "$\\mbox{Norm_Col}_i = \\frac{\\mbox{Col}_i - \\mu_i}{\\sigma_i}$\n",
    "\n",
    "where $\\mbox{Col}_i$ is the $i$th column of $X$, $\\mu_i$ is average of the values in the $i$th column of $X$, and $\\sigma_i$ is the standard deviation of the values in the $i$th column of $X$. In other words, mean normalization is performed by subtracting from each column of $X$ the average of its values, and then by dividing by the standard deviation of its values. In the space below, you will first calculate the average and standard deviation of each column of $X$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2472.069  2522.805  2482.297  2499.834  2416.431  2490.864  2405.188\n",
      "  2438.992  2456.794  2525.369  2587.749  2576.408  2456.757  2549.584\n",
      "  2468.243  2535.525  2481.783  2433.406  2521.8    2567.891]\n",
      "\n",
      "[ 1456.48166904  1472.59227112  1434.15642898  1452.81393112  1431.15902933\n",
      "  1444.34398725  1463.30889721  1409.74889606  1449.82718403  1457.55536253\n",
      "  1425.35135668  1441.96568043  1455.35895227  1453.47923031  1454.29284395\n",
      "  1465.11987748  1453.48184093  1460.27087253  1429.0945777   1415.17730377]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Average of the values in each column of X\n",
    "ave_cols = X.mean(axis=0)\n",
    "print(ave_cols)\n",
    "print()\n",
    "# Standard Deviation of the values in each column of X\n",
    "std_cols = X.std(axis=0)\n",
    "print(std_cols)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have done the above calculations correctly, then `ave_cols` and `std_cols`, should both be vectors with shape `(20,)` since $X$ has 20 columns. You can verify this by filling the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20,)\n",
      "(20,)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of ave_cols\n",
    "print(ave_cols.shape)\n",
    "\n",
    "# Print the shape of std_cols\n",
    "print(std_cols.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now take advantage of Broadcasting to calculate the mean normalized version of $X$ in just one line of code using the equation above. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean normalize X\n",
    "X_norm = (X - ave_cols) / std_cols\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have performed the mean normalization correctly, then the average of all the elements in $X_{\\tiny{\\mbox{norm}}}$ should be close to zero, and they should be evenly distributed in some small interval around zero. You can verify this by filing the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.70414851306e-18\n",
      "-1.72118399075\n",
      "1.72970081755\n"
     ]
    }
   ],
   "source": [
    "# Print the average of all the values of X_norm\n",
    "print(np.mean(X_norm))\n",
    "\n",
    "# Print the average of the minimum value in each column of X_norm\n",
    "print(np.mean(X_norm.min(axis=0)))\n",
    "\n",
    "# Print the average of the maximum value in each column of X_norm\n",
    "print(np.mean(X_norm.max(axis=0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should note that since $X$ was created using random integers, the above values will vary. \n",
    "\n",
    "# Data Separation\n",
    "\n",
    "After the data has been mean normalized, it is customary in machine learnig to split our dataset into three sets:\n",
    "\n",
    "1. A Training Set\n",
    "2. A Cross Validation Set\n",
    "3. A Test Set\n",
    "\n",
    "The dataset is usually divided such that the Training Set contains 60% of the data, the Cross Validation Set contains 20% of the data, and the Test Set contains 20% of the data. \n",
    "\n",
    "In this part of the lab you will separate `X_norm` into a Training Set, Cross Validation Set, and a Test Set. Each data set will contain rows of `X_norm` chosen at random, making sure that we don't pick the same row twice. This will guarantee that all the rows of `X_norm` are chosen and randomly distributed among the three new sets.\n",
    "\n",
    "You will start by creating a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`. You can do this by using the `np.random.permutation()` function. The `np.random.permutation(N)` function creates a random permutation of integers from 0 to `N - 1`. Let's see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 2 3 0 1]\n"
     ]
    }
   ],
   "source": [
    "# We create a random permutation of integers 0 to 4\n",
    "rp = np.random.permutation(5)\n",
    "print(rp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do\n",
    "\n",
    "In the space below create a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`. You can do this in one line of code by extracting the number of rows of `X_norm` using the `shape` attribute and then passing it to the  `np.random.permutation()` function. Remember the `shape` attribute returns a tuple with two numbers in the form `(rows,columns)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[662 172 423 743 634 679 309 339 260 932 622 609 503 332 506 158 667 402\n",
      " 584 299 937 293 893 819 106 437 510 343 899 740 898 247 176 218  80 906\n",
      "   9 397 375 651 124  44 684 195 502 252 686 489 341 732 236 758 336 150\n",
      " 921 756 237 792 364 801  60 507 416  56 290 728 598 689 903 711 313 883\n",
      " 521 241 322  79 333 774 142 536 934 537 186  76 825 862 463 928 550 366\n",
      " 918 188 219 632 865 827 233 604 365 385 970 353 559 159 258 753 540 759\n",
      " 497 910 949 259 407 936 169 852 558 871 818 325 116 931 215 165 175 839\n",
      " 697 702 449 225 900 786 725 317 990 539 194 996 294 298 185  18 107 468\n",
      " 399  96  78 700 363 841  22 499 228  55 227 239 562 576 685 456 636 747\n",
      " 853 132 892 256 419 646 663 141 473 941 424 972 630 735 118 682 493 330\n",
      " 547 548 174 345 783 703 850 692 844 408 864 691 982   4  53 388  58 355\n",
      " 523 457 368 952 223 837 654 264 580 987 267 846   1 939 613 445  73 860\n",
      " 803 306 125 956 373 577 879 452 171 212 933 601 925 154 645 250 383 354\n",
      " 409 816 518 207 297 857 381 922 935 814 572 542  63 914 586 614 615 123\n",
      " 967  57 312  65  67 464 441 583 376 920 787 249 362 752  54 139 923 919\n",
      " 698 148 817 948 822 455 347 491 720 434 529 192 527 448 944 661  81 733\n",
      " 986  47 610 993 263 596 556 478 327 884 262 235 672 147 705 983 187 268\n",
      " 916 210 877 840  97 321 331 975 515 413 300 133  39 315 102 358 427 557\n",
      " 401 716 138 157 538 676 270  45 522  71 638 809 796 500  85 197 712 480\n",
      "  24 744 122 286 240 581  26 769 303 266 161 398 988 600 605 779 971 275\n",
      " 644  40 104 319 495 392 202 789 957 302 905 886 535 526 190 232 575 565\n",
      " 465 578 357 812 474  89 904 180 400 320 833 182 516 595 346 230 798 856\n",
      " 582 167 714 788 356 443 881 811 761 454 999  21 896 611 791 326 701 750\n",
      " 479 209 177 386  84 832  66 438 734 410  77  64 762 261 105 334 997 670\n",
      " 909  82 902 135 471  10 940 806 845 894 942 929 173 461 831 274   2  25\n",
      " 318 826 797 394 458 406 768 283 745 512 907  27 945 737 748 567  15  38\n",
      " 120 802 984 763 216 573 403 509 208 414 664 348 484 755 872 784 606 954\n",
      " 160  70  16 751 418 978 926 593 189 889 639  41 687 660 776 777 754 709\n",
      "  51 435 226 901 991  36 459 843 560 998 163 422 295 649 829 669 498  61\n",
      " 764 369 959 648 619 946 164  20 193 566 876 338 279  31 191  86  95 284\n",
      " 950 821 492 739 808 412 969 352 719 178 717 431  23   0 805 657 794  68\n",
      " 680 109 432 655 640 555 307  90 335 301 574 211  19 121 968 272 666 594\n",
      " 425  88 514 859 730  92 508 681 953 742 708 960 276 726 621 979 897 328\n",
      " 466 380 677 994   7 483 608 643 146  74 977 391 285 296  94 771 184 824\n",
      " 731 885  30 616 842 985  48 694  13 741 203 767 287 246 869 265 870   6\n",
      " 119 927 736 361 962 878 444 849 992 129 683  43 134 384 624 460 552 472\n",
      " 544 592 113 746 915 511 688 370 810 626 477 848 131 255 405 912 282 198\n",
      " 628 838 668 344 629 757 637  87 561 183 882 599 891 721 715 770 277 674\n",
      " 723  59 707 820 462 804 415 749 476 314 665 446 470 323 620  75 534 108\n",
      "  12 738 238 541 505 229 257 517 868 887 166 181 974 254 695 100 973 785\n",
      " 501 329 374 706 823 162 587 713 350 612 217 775 955 145 475 653 568 404\n",
      " 563 324 895 569  37 947 533 494  29 911 453 834 778 421 585 888 231  49\n",
      " 590 551 467   3 469 519 221 205 658 429  52 965 224 248 531  46 311 430\n",
      " 170 554 289  91 206 382 243 951 251 245 532 234 724  33 253 930 564 799\n",
      " 433 151 271 213 699 855 390 938 766 117  69 242 656 214 642 772 513 153\n",
      " 450 727 337 155 836 308  32 482 439 379 128  99 781 588 149 800 589 115\n",
      "  42 553 371 549 436 627 490 652 378 591 428 635 570 126 528 943 387  34\n",
      " 411 780 602 101 487 867 201 835 220  83 633 650 292 396 675 144  14 908\n",
      " 485 340 890 729 152 486  62 617 426 447 813 917 623 765 204 481 156 304\n",
      " 111 196 420 525 530  35 579 866 349 137 854 851  50 961 199 545 807 963\n",
      " 367 722 546 351 964 693 222 389 281 130 395 981 861 625 103 641 847 417\n",
      " 305 200 647  11 136 597 393 451  17  98 372 710 976 989 114 980 269 607\n",
      " 966 873 440 342 316 359 360 782   8 273 603 631 291 958 760 143 913 795\n",
      "  72 524 773 520 488 815 571 496 377 924 874 140 875 168 288 112 863 618\n",
      " 179 678 704 278 858  28 696 880 995  93 110   5 690 504 718 127 790 442\n",
      " 310 673 659 793 830 828 280 543 244 671]\n"
     ]
    }
   ],
   "source": [
    "# Create a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`\n",
    "row_indices = np.random.permutation(X_norm.shape[0])\n",
    "print(row_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can create the three datasets using the `row_indices` ndarray to select the rows that will go into each dataset. Rememeber that the Training Set contains 60% of the data, the Cross Validation Set contains 20% of the data, and the Test Set contains 20% of the data. Each set requires just one line of code to create. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make any necessary calculations.\n",
    "# You can save your calculations into variables to use later.\n",
    "\n",
    "# Create a Training Set\n",
    "X_train = X_norm[row_indices[:600],]\n",
    "\n",
    "# Create a Cross Validation Set\n",
    "X_crossVal = X_norm[row_indices[600:800],]\n",
    "\n",
    "# Create a Test Set\n",
    "X_test = X_norm[row_indices[800:1000],]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you performed the above calculations correctly, then `X_tain` should have 600 rows and 20 columns, `X_crossVal` should have 200 rows and 20 columns, and `X_test` should have 200 rows and 20 columns. You can verify this by filling the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 20)\n",
      "(200, 20)\n",
      "(200, 20)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of X_train\n",
    "print(X_train.shape)\n",
    "\n",
    "# Print the shape of X_crossVal\n",
    "print(X_crossVal.shape)\n",
    "\n",
    "# Print the shape of X_test\n",
    "print(X_test.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
